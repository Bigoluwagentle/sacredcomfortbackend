import Anthropic from '@anthropic-ai/sdk';
import OpenAI from 'openai';
import logger from '../../utils/logger.js';

const anthropic = new Anthropic({
  apiKey: process.env.ANTHROPIC_API_KEY,
});

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

export const generateChatResponse = async ({
  systemPrompt,
  conversationHistory,
  userMessage,
  maxTokens = 1500,
}) => {
  const messages = [
    ...conversationHistory.map((msg) => ({
      role: msg.role,
      content: msg.content,
    })),
    { role: 'user', content: userMessage },
  ];

  try {
    const response = await anthropic.messages.create({
      model: 'claude-opus-4-6',
      max_tokens: maxTokens,
      system: systemPrompt,
      messages,
    });
    logger.info('Response generated by Claude');
    return response.content[0].text;
  } catch (claudeError) {
    logger.warn(`Claude failed: ${claudeError.message}. Falling back to OpenAI...`);
  }

  try {
    const response = await openai.chat.completions.create({
      model: 'gpt-4o',
      max_tokens: maxTokens,
      messages: [
        { role: 'system', content: systemPrompt },
        ...messages,
      ],
    });
    logger.info('Response generated by OpenAI fallback');
    return response.choices[0].message.content;
  } catch (openaiError) {
    logger.error(`OpenAI fallback failed: ${openaiError.message}`);
    throw new Error('AI service is temporarily unavailable. Please try again.');
  }
};

export const extractMemoryFromConversation = async (conversationText) => {
  const prompt = `Based on this conversation, extract key facts about the user to remember for future conversations. Return ONLY a valid JSON object with no extra text:

${conversationText}

Return this exact format:
{
  "personalContext": [],
  "recurringIssues": [],
  "progressNotes": [],
  "relationshipContext": []
}`;

  try {
    const response = await anthropic.messages.create({
      model: 'claude-opus-4-6',
      max_tokens: 500,
      messages: [{ role: 'user', content: prompt }],
    });
    return JSON.parse(response.content[0].text.trim());
  } catch (claudeError) {
    logger.warn(`Claude memory extraction failed. Falling back to OpenAI...`);
  }

  try {
    const response = await openai.chat.completions.create({
      model: 'gpt-4o',
      max_tokens: 500,
      messages: [{ role: 'user', content: prompt }],
    });
    return JSON.parse(response.choices[0].message.content.trim());
  } catch (error) {
    logger.error(`Memory extraction failed: ${error.message}`);
    return {
      personalContext: [],
      recurringIssues: [],
      progressNotes: [],
      relationshipContext: [],
    };
  }
};

export const detectEmotionsAndTopics = async (message) => {
  const prompt = `Analyze this message and return ONLY a valid JSON object with no extra text:

"${message}"

Return this exact format:
{
  "emotions": ["anxiety"],
  "topics": ["work"],
  "distressLevel": 5,
  "crisisDetected": false
}

emotions must be from: anxiety, sadness, anger, joy, confusion, gratitude, fear, loneliness, hope, grief
topics must be from: relationships, health, work, faith, family, finances, loss, identity, addiction, purpose
distressLevel is 1-10
crisisDetected is true only if there are signs of suicidal ideation or self harm`;

  try {
    const response = await anthropic.messages.create({
      model: 'claude-opus-4-6',
      max_tokens: 200,
      messages: [{ role: 'user', content: prompt }],
    });
    return JSON.parse(response.content[0].text.trim());
  } catch (claudeError) {
    logger.warn(`Claude emotion detection failed. Falling back to OpenAI...`);
  }

  try {
    const response = await openai.chat.completions.create({
      model: 'gpt-4o',
      max_tokens: 200,
      messages: [{ role: 'user', content: prompt }],
    });
    return JSON.parse(response.choices[0].message.content.trim());
  } catch (error) {
    logger.error(`Emotion detection failed: ${error.message}`);
    return {
      emotions: [],
      topics: [],
      distressLevel: 0,
      crisisDetected: false,
    };
  }
};